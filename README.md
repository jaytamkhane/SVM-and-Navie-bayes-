# SVM & Naïve Bayes Assignment

This repository contains solutions to the theoretical and practical questions for the **SVM & Naïve Bayes Assignment**. The assignment covers essential concepts, mathematical insights, and practical implementations of Support Vector Machines (SVM) and Naïve Bayes classifiers.

## Structure of the Repository

The repository is organized as follows:

1. **Theoretical Questions**
   - Detailed answers to theoretical questions about SVM and Naïve Bayes, including concepts like kernels, parameters (C, gamma), Laplace smoothing, and more.

2. **Practical Implementations**
   - Python scripts implementing various machine learning tasks:
     - Training SVM classifiers and regressors with different kernels and parameters.
     - Implementing Gaussian, Multinomial, and Bernoulli Naïve Bayes classifiers.
     - Model evaluation using metrics such as accuracy, precision, recall, F1-Score, ROC-AUC, and more.
     - Techniques like GridSearchCV, Recursive Feature Elimination (RFE), and feature scaling.
     - Visualizations of decision boundaries, confusion matrices, and precision-recall curves.

## Highlights of the Assignment

### Theoretical
- Explained the differences between hard and soft margin SVMs.
- Discussed the kernel trick and compared linear, polynomial, and RBF kernels.
- Covered key differences between Gaussian, Multinomial, and Bernoulli Naïve Bayes.
- Illustrated the advantages and disadvantages of each approach.

### Practical
- Python programs to implement:
  - **SVM Classifiers and Regressors**: Using datasets such as Iris, Wine, and Breast Cancer.
  - **Naïve Bayes Classifiers**: For tasks like text classification, spam detection, and binary classification.
  - **Model Optimization**: Hyperparameter tuning using GridSearchCV.
  - **Feature Engineering**: Techniques like RFE and SelectKBest for feature selection.
  - **Performance Metrics**: Evaluations with metrics like Log Loss, PR-AUC, and more.
